┌──────────────────────────────────────────────────────────┐
│                        USER QUERY                        │
│                     (string input)                       │
└───────────────────────────┬──────────────────────────────┘
                            │
                            ▼
┌──────────────────────────────────────────────────────────┐
│ EMBEDDING                                                 │
│ embed(text)                                              │
│ src/utils/llm.py                                         │
│                                                          │
│ - SentenceTransformer (all-MiniLM-L6-v2)                 │
│ - normalize_embeddings=True                              │
│ - returns List[float]                                    │
└───────────────────────────┬──────────────────────────────┘
                            │
                            ▼
┌──────────────────────────────────────────────────────────┐
│ INITIALIZE STATE                                         │
│ init_state_node                                          │
│ src/agent/graph.py                                       │
│                                                          │
│ creates AgentState with:                                 │
│ - query, query_embedding                                 │
│ - iteration, api_calls                                   │
│ - cache flags, counters                                  │
│ - empty documents / chunks                               │
│ - scoring placeholders                                   │
│                                                          │
│ NOTE: state is per-query, ephemeral                      │
└───────────────────────────┬──────────────────────────────┘
                            │
                            ▼
┌──────────────────────────────────────────────────────────┐
│ TIER 1: QUERY CACHE LOOKUP                               │
│ query_cache_node                                         │
│ src/agent/graph.py                                       │
│                                                          │
│ calls:                                                   │
│   VectorCache.search_query()                             │
│   src/retrieval/cache.py                                 │
│                                                          │
│ search_query internally:                                 │
│   - ChromaDB query (query_cache collection)              │
│   - cosine similarity                                    │
│   - TTL check                                            │
│   - LRU touch                                            │
│                                                          │
│ outputs:                                                 │
│   state.cache_hit        (bool)                           │
│   state.cache_payload    (answer + metadata)             │
│   state.query_cache_hits ++ (if hit)                     │
│   state.api_calls_saved  ++ (if hit)                     │
│                                                          │
│ IMPORTANT:                                                │
│ - DOES NOT set final_answer                              │
│ - DOES NOT call LLM                                     │
└───────────────┬─────────────────────────────┬────────────┘
                │ cache_hit = TRUE            │ cache_hit = FALSE
                ▼                             ▼
┌──────────────────────────────────────┐     ┌──────────────────────────────────────────┐
│ PROMPT PATH (CACHE AS CONTEXT)       │     │ ENTER RETRIEVAL LOOP                     │
│ (LLM STILL RUNS)                     │     │                                          │
└───────────────┬──────────────────────┘     └────────────────┬─────────────────────────┘
                │                                              │
                ▼                                              ▼
        ┌──────────────────────────────────────────────────────────┐
        │ TIER 2: CHUNK STORE SEARCH                               │
        │ chunk_store_search_node                                  │
        │ src/agent/graph.py                                       │
        │                                                          │
        │ calls:                                                   │
        │   VectorCache.search_chunks()                            │
        │   src/retrieval/cache.py                                 │
        │                                                          │
        │ search_chunks enforces:                                  │
        │   - cosine similarity (chunk threshold)                  │
        │   - monotonic early exit                                 │
        │   - max_chunks_per_doc                                   │
        │                                                          │
        │ outputs:                                                 │
        │   state.anchor_chunks                                    │
        │   state.chunk_store_hits += len(chunks)                  │
        │   state.chunk_store_size                                 │
        │   state.num_anchor_chunks                                │
        └───────────────────────────┬──────────────────────────────┘
                                    │
                                    ▼
        ┌──────────────────────────────────────────────────────────┐
        │ SCORE EVIDENCE                                           │
        │ score_node                                               │
        │ src/scoring/score.py                                     │
        │                                                          │
        │ computes per anchor chunk:                               │
        │   - similarity_score                                    │
        │   - recency_score                                       │
        │                                                          │
        │ aggregates to document-level:                            │
        │   - max chunk score per doc                              │
        │   - avg_doc_score                                       │
        │   - diversity bonus                                     │
        │                                                          │
        │ updates:                                                 │
        │   state.retrieval_score                                  │
        │   state.num_docs                                         │
        │   state.doc_scores                                       │
        │   state.confident                                        │
        │   state.prev_retrieval_scores                            │
        └───────────────────────────┬──────────────────────────────┘
                                    │
                                    ▼
        ┌──────────────────────────────────────────────────────────┐
        │ DECISION NODE                                            │
        │ decision_node                                            │
        │ src/agent/decisions.py                                   │
        │                                                          │
        │ checks (in order):                                       │
        │   - max_iterations                                       │
        │   - api_calls limit                                      │
        │   - no evidence + exhausted                              │
        │   - stagnation detection                                 │
        │   - score ≥ threshold AND confident                      │
        │                                                          │
        │ sets:                                                    │
        │   state.decision = STOP | FETCH_MORE                     │
        │   state.stop_reason                                      │
        │                                                          │
        │ NOTE: cache_hit does NOT force STOP                      │
        └───────────────┬─────────────────────────────┬────────────┘
                        │ STOP                        │ FETCH_MORE
                        ▼                             ▼
┌──────────────────────────────────────────┐     ┌──────────────────────────────────────────┐
│ CONTEXT EXPANSION + PROMPT BUILD         │     │ TIER 3: PUBMED FETCH                     │
│ prompt_node                              │     │ pubmed_fetch_node                        │
│ src/agent/graph.py                      │     │ src/retrieval/pubmed.py                  │
│                                          │     │                                          │
│ internally calls:                        │     │ calls:                                   │
│   build_final_prompt()                   │     │   PubMed E-Utilities API                 │
│   src/utils/prompt.py                    │     │                                          │
│                                          │     │ extracts:                                │
│ build_final_prompt does:                 │     │   - abstract                             │
│   - context_expansion_node()             │     │   - conclusion (optional)                │
│   - flatten_context_from_state()         │     │                                          │
│   - inject cached answer (REFERENCE)     │     │ embeds via:                              │
│   - inject chat memory (optional)        │     │   embed(text)                            │
│   - build evidence block                 │     │                                          │
│                                          │     │ updates:                                 │
│ calls:                                   │     │   state.documents                        │
│   call_llm()                             │     │   state.doc_chunks_map                   │
│   src/utils/llm.py                       │     │   VectorCache.add_chunks()               │
│                                          │     │   state.api_calls ++                     │
│ sets:                                    │     │                                          │
│   state.final_answer                     │     └───────────────┬──────────────────────────┘
└──────────────────────────┬───────────────┘                     │
                           │                                     │
                           ▼                                     │
┌──────────────────────────────────────────────────────────┐     │
│ CHAT MEMORY UPDATE                                       │◀────┘
│ ChatMemory.update                                        │
│ src/utils/memory.py                                      │
│                                                          │
│ - summary-only memory                                    │
│ - summarizes every N interactions                        │
│ - uses LLM internally                                   │
│ - NOT stored in AgentState                               │
└───────────────────────────┬──────────────────────────────┘
                            │
                            ▼
┌──────────────────────────────────────────────────────────┐
│ CACHE ADMISSION CHECK                                    │
│ cache_write_node                                         │
│ src/agent/graph.py                                       │
│                                                          │
│ calls:                                                   │
│   should_cache()                                         │
│   src/agent/decisions.py                                 │
│                                                          │
│ if TRUE:                                                 │
│   VectorCache.add_query()                                │
│   src/retrieval/cache.py                                 │
│                                                          │
│ stored payload includes:                                 │
│   - final_answer                                         │
│   - retrieval_score                                      │
│   - doc_scores                                           │
│   - num_docs                                             │
│                                                          │
│ LRU + TTL enforced                                       │
└───────────────────────────┬──────────────────────────────┘
                            │
                            ▼
┌──────────────────────────────────────────────────────────┐
│                        END                               │
│              Final AgentState returned                   │
└──────────────────────────────────────────────────────────┘
